{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidCastroPena/credit-models/blob/model_1_XGBBoostSurvival/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QAGuLc7Gc8V",
        "outputId": "cb8dea1a-f5be-4356-bc90-adb9489473eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.utils import resample\n",
        "# Paths to your files\n",
        "import pandas as pd\n",
        "\n",
        "# First attempt with folder ID\n",
        "path1_10_present = '/content/drive/My Drive/11S7cbE_9RF5lE2TuDVrIgcdrRnwJjwTY/10_present.csv'\n",
        "path1_91_09 = '/content/drive/My Drive/11S7cbE_9RF5lE2TuDVrIgcdrRnwJjwTY/91_09.csv'\n",
        "\n",
        "# Second attempt with folder name\n",
        "path2_10_present = '/content/drive/My Drive/MS&E246/10_present.csv'\n",
        "path2_91_09 = '/content/drive/My Drive/MS&E246/91_09.csv'\n",
        "\n",
        "# Try reading with both paths\n",
        "try:\n",
        "    # Try first path\n",
        "    df_10_present = pd.read_csv(path1_10_present)\n",
        "    df_91_09 = pd.read_csv(path1_91_09)\n",
        "    print(\"Successfully read from folder ID path\")\n",
        "except:\n",
        "    try:\n",
        "        # Try second path\n",
        "        df_10_present = pd.read_csv(path2_10_present)\n",
        "        df_91_09 = pd.read_csv(path2_91_09)\n",
        "        print(\"Successfully read from folder name path\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnD5f7yLWnus",
        "outputId": "ab051042-6e2f-4b8b-d964-a4d2635fe9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4238d0bcc21f>:22: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_10_present = pd.read_csv(path2_10_present)\n",
            "<ipython-input-3-4238d0bcc21f>:23: DtypeWarning: Columns (12,13,14,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_91_09 = pd.read_csv(path2_91_09)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully read from folder name path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "path1_10_present = '/content/drive/My Drive/11S7cbE_9RF5lE2TuDVrIgcdrRnwJjwTY/10_present.csv'\n",
        "path1_91_09 = '/content/drive/My Drive/11S7cbE_9RF5lE2TuDVrIgcdrRnwJjwTY/91_09.csv'\n",
        "\n",
        "path2_10_present = '/content/drive/My Drive/MS&E246/10_present.csv'\n",
        "path2_91_09 = '/content/drive/My Drive/MS&E246/91_09.csv'\n",
        "\n",
        "# Attempt to read the datasets from the first paths, then fallback to second paths if needed\n",
        "try:\n",
        "    df_10_present = pd.read_csv(path1_10_present)\n",
        "    df_91_09 = pd.read_csv(path1_91_09)\n",
        "    print(\"Successfully read from folder ID path\")\n",
        "except:\n",
        "    try:\n",
        "        df_10_present = pd.read_csv(path2_10_present)\n",
        "        df_91_09 = pd.read_csv(path2_91_09)\n",
        "        print(\"Successfully read from folder name path\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Align columns (ensure both datasets have the same column order and names)\n",
        "# Find common columns\n",
        "common_columns = list(set(df_10_present.columns).intersection(set(df_91_09.columns)))\n",
        "df_10_present = df_10_present[common_columns]\n",
        "df_91_09 = df_91_09[common_columns]\n",
        "\n",
        "# Concatenate the datasets (91_09 above, 10_present below)\n",
        "df_combined = pd.concat([df_91_09, df_10_present], ignore_index=True)\n",
        "\n",
        "# Output the shape and preview of the combined dataframe\n",
        "print(f\"Combined dataset shape: {df_combined.shape}\")\n",
        "print(df_combined.head())\n",
        "\n",
        "# Save the combined dataset to a new file if needed\n",
        "output_path = '/content/drive/My Drive/MS&E246/combined_dataset.csv'\n",
        "df_combined.to_csv(output_path, index=False)\n",
        "print(f\"Combined dataset saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bosei-uoj0Ph",
        "outputId": "17fc7d0c-ae94-403a-b587-8b504b54a809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b84f50aac373>:17: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_10_present = pd.read_csv(path2_10_present)\n",
            "<ipython-input-4-b84f50aac373>:18: DtypeWarning: Columns (12,13,14,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_91_09 = pd.read_csv(path2_91_09)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully read from folder name path\n",
            "Combined dataset shape: (218095, 38)\n",
            "   Program  TermInMonths  ApprovalFiscalYear   AsOfDate BorrState  \\\n",
            "0      504           240                1991  9/30/2024        CA   \n",
            "1      504           240                1991  9/30/2024        UT   \n",
            "2      504           240                1991  9/30/2024        WY   \n",
            "3      504           120                1991  9/30/2024        IN   \n",
            "4      504           240                1991  9/30/2024        IN   \n",
            "\n",
            "  ThirdPartyLender_Name BusinessAge  BorrZip CDC_State  \\\n",
            "0                   NaN         NaN    92121        CA   \n",
            "1                   NaN         NaN    84115        UT   \n",
            "2                   NaN         NaN    83001        UT   \n",
            "3                   NaN         NaN    47620        IN   \n",
            "4                   NaN         NaN    46514        IN   \n",
            "\n",
            "                         CDC_Name  ... FranchiseCode ThirdPartyLender_City  \\\n",
            "0  CDC Small Business Finance Cor  ...           NaN                   NaN   \n",
            "1  Mountain West Small Business F  ...           NaN                   NaN   \n",
            "2  Mountain West Small Business F  ...           NaN                   NaN   \n",
            "3  Indiana Statewide Certified De  ...           NaN                   NaN   \n",
            "4  Indiana Statewide Certified De  ...           NaN                   NaN   \n",
            "\n",
            "  GrossChargeOffAmount                  CDC_Street GrossApproval  \\\n",
            "0                    0  2448 Historic Decatur Road      175000.0   \n",
            "1                    0        2595 East 3300 South      231000.0   \n",
            "2                    0        2595 East 3300 South      370000.0   \n",
            "3                    0       4181 East 96th Street      561000.0   \n",
            "4                    0       4181 East 96th Street      310000.0   \n",
            "\n",
            "         BorrCity BusinessType  DeliveryMethod  CongressionalDistrict  \\\n",
            "0       SAN DIEGO  CORPORATION             504                   49.0   \n",
            "1  SALT LAKE CITY  CORPORATION             504                    2.0   \n",
            "2         JACKSON  CORPORATION             504                    0.0   \n",
            "3    MOUNT VERNON  CORPORATION             504                    8.0   \n",
            "4         ELKHART  CORPORATION             504                    2.0   \n",
            "\n",
            "  ProjectCounty  \n",
            "0     SAN DIEGO  \n",
            "1     SALT LAKE  \n",
            "2         TETON  \n",
            "3         POSEY  \n",
            "4       ELKHART  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "Combined dataset saved to: /content/drive/My Drive/MS&E246/combined_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating two files"
      ],
      "metadata": {
        "id": "In0a_-eakGSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df_91_09, df_10_present], ignore_index=True)\n",
        "print(f\"Combined dataset shape: {df_combined.shape}\")\n",
        "print(df_combined.head())\n",
        "\n",
        "# Save the combined dataset to a new file if needed\n",
        "output_path = '/content/drive/My Drive/MS&E246/combined_dataset.csv'\n",
        "df_combined.to_csv(output_path, index=False)\n",
        "print(f\"Combined dataset saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvPL1IcAkDXF",
        "outputId": "057c137e-e4b2-4e11-86c6-34fa8b1ce8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (218095, 38)\n",
            "   Program  TermInMonths  ApprovalFiscalYear   AsOfDate BorrState  \\\n",
            "0      504           240                1991  9/30/2024        CA   \n",
            "1      504           240                1991  9/30/2024        UT   \n",
            "2      504           240                1991  9/30/2024        WY   \n",
            "3      504           120                1991  9/30/2024        IN   \n",
            "4      504           240                1991  9/30/2024        IN   \n",
            "\n",
            "  ThirdPartyLender_Name BusinessAge  BorrZip CDC_State  \\\n",
            "0                   NaN         NaN    92121        CA   \n",
            "1                   NaN         NaN    84115        UT   \n",
            "2                   NaN         NaN    83001        UT   \n",
            "3                   NaN         NaN    47620        IN   \n",
            "4                   NaN         NaN    46514        IN   \n",
            "\n",
            "                         CDC_Name  ... FranchiseCode ThirdPartyLender_City  \\\n",
            "0  CDC Small Business Finance Cor  ...           NaN                   NaN   \n",
            "1  Mountain West Small Business F  ...           NaN                   NaN   \n",
            "2  Mountain West Small Business F  ...           NaN                   NaN   \n",
            "3  Indiana Statewide Certified De  ...           NaN                   NaN   \n",
            "4  Indiana Statewide Certified De  ...           NaN                   NaN   \n",
            "\n",
            "  GrossChargeOffAmount                  CDC_Street GrossApproval  \\\n",
            "0                    0  2448 Historic Decatur Road      175000.0   \n",
            "1                    0        2595 East 3300 South      231000.0   \n",
            "2                    0        2595 East 3300 South      370000.0   \n",
            "3                    0       4181 East 96th Street      561000.0   \n",
            "4                    0       4181 East 96th Street      310000.0   \n",
            "\n",
            "         BorrCity BusinessType  DeliveryMethod  CongressionalDistrict  \\\n",
            "0       SAN DIEGO  CORPORATION             504                   49.0   \n",
            "1  SALT LAKE CITY  CORPORATION             504                    2.0   \n",
            "2         JACKSON  CORPORATION             504                    0.0   \n",
            "3    MOUNT VERNON  CORPORATION             504                    8.0   \n",
            "4         ELKHART  CORPORATION             504                    2.0   \n",
            "\n",
            "  ProjectCounty  \n",
            "0     SAN DIEGO  \n",
            "1     SALT LAKE  \n",
            "2         TETON  \n",
            "3         POSEY  \n",
            "4       ELKHART  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "Combined dataset saved to: /content/drive/My Drive/MS&E246/combined_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30,641 CANCLD loans. Q1: IF loanstatus=chgoff & grosschargeoff different from 0; should be removed? Q2: missing values was created based on whether loanstatus is empty. is this right?"
      ],
      "metadata": {
        "id": "4SDf1jCb8CkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the combined dataset\n",
        "combined_path = '/content/drive/My Drive/MS&E246/combined_dataset.csv'\n",
        "df = pd.read_csv(combined_path)\n",
        "\n",
        "# Step 1: Create a copy of the dataset\n",
        "df_cleaned = df.copy()\n",
        "print(f\"Initial dataset shape: {df_cleaned.shape}\")\n",
        "\n",
        "# Step 2: Remove loans labeled \"Canceled\"\n",
        "if 'LoanStatus' in df_cleaned.columns:\n",
        "    df_cleaned = df_cleaned[df_cleaned['LoanStatus'] != 'CANCLD']\n",
        "    print(f\"After removing 'Canceled' loans: {df_cleaned.shape}\")\n",
        "else:\n",
        "    print(\"'LoanStatus' column not found. Skipping 'Canceled' filtering.\")\n",
        "\n",
        "# Step 3: Handle blank or missing LoanStatus\n",
        "# Create a binary variable `missingStatus`\n",
        "if 'LoanStatus' in df_cleaned.columns:\n",
        "    df_cleaned['missingStatus'] = df_cleaned['LoanStatus'].isnull() | (df_cleaned['LoanStatus'].str.strip() == \"\")\n",
        "    df_cleaned['missingStatus'] = df_cleaned['missingStatus'].astype(int)\n",
        "    print(f\"After creating 'missingStatus': {df_cleaned.shape}\")\n",
        "    print(f\"Number of rows with missing statuses: {df_cleaned['missingStatus'].sum()}\")\n",
        "else:\n",
        "    print(\"'LoanStatus' column not found. Skipping 'missingStatus' creation.\")\n",
        "\n",
        "# Step 4: Save the updated dataset\n",
        "updated_path = '/content/drive/My Drive/MS&E246/cleaned_with_missing_status.csv'\n",
        "df_cleaned.to_csv(updated_path, index=False)\n",
        "print(f\"Updated dataset saved to: {updated_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Aop70c6OC1",
        "outputId": "6742c2c2-d293-43aa-debc-1619a898451a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6a3024ae9c8b>:3: DtypeWarning: Columns (5,6,19,28,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(combined_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (218095, 38)\n",
            "After removing 'Canceled' loans: (187454, 38)\n",
            "After creating 'missingStatus': (187454, 39)\n",
            "Number of rows with missing statuses: 350\n",
            "Updated dataset saved to: /content/drive/My Drive/MS&E246/cleaned_with_missing_status.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Splitting should be done by calendar dates\n",
        "'''\n",
        "Proposed Splitting Strategy\n",
        "To create training, validation, and testing sets that align with these economic shifts, split the data based on these crises:\n",
        "\n",
        "Training Set (Pre-Crisis Stability and Dot-Com Era):\n",
        "Timeframe: 1990–2006.\n",
        "Rationale: This period includes relatively stable economic years, the Dot-Com bubble, and its aftermath. Training the model on this data helps it learn patterns from normal and mildly volatile periods.\n",
        "\n",
        "Validation Set (2007–2015, Financial Crisis and Recovery):\n",
        "Timeframe: 2007–2015.\n",
        "Rationale: Includes the 2007–2008 financial crisis, the subsequent Great Recession, and the recovery phase. This period helps validate how well the model generalizes to high-stress financial environments.\n",
        "\n",
        "Testing Set (COVID-19 Pandemic and Current Data):\n",
        "Timeframe: 2016–2024.\n",
        "Rationale: Includes recent years leading up to and during the COVID-19 pandemic, as well as the post-pandemic recovery. This evaluates the model's robustness on recent economic disruptions.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "Lz3WYoWl8T1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "bb7a3bd0-21ae-4390-c9ed-548645454449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nProposed Splitting Strategy\\nTo create training, validation, and testing sets that align with these economic shifts, split the data based on these crises:\\n\\nTraining Set (Pre-Crisis Stability and Dot-Com Era):\\n\\nTimeframe: 1990–2006.\\nRationale: This period includes relatively stable economic years, the Dot-Com bubble, and its aftermath. Training the model on this data helps it learn patterns from normal and mildly volatile periods.\\nValidation Set (2007–2015, Financial Crisis and Recovery):\\n\\nTimeframe: 2007–2015.\\nRationale: Includes the 2007–2008 financial crisis, the subsequent Great Recession, and the recovery phase. This period helps validate how well the model generalizes to high-stress financial environments.\\nTesting Set (COVID-19 Pandemic and Current Data):\\n\\nTimeframe: 2016–2024.\\nRationale: Includes recent years leading up to and during the COVID-19 pandemic, as well as the post-pandemic recovery. This evaluates the model's robustness on recent economic disruptions.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection: two strategies--using Kai's Chi2 test and via logistic regression using literature suggested variables\n",
        "\n",
        "'''\n",
        "PIF: Paid In Full.\n",
        "CANCLD: Canceled.\n",
        "CHGOFF: Charged Off (Default).\n",
        "nan: Missing/Not Available.\n",
        "EXEMPT: Exempt (special status, possibly regulatory or administrative).\n",
        "If you are focusing on predicting defaults, you would typically:\n",
        "\n",
        "Treat CHGOFF as a default (1).\n",
        "Treat PIF and potentially EXEMPT as non-defaults (0).\n",
        "Exclude or handle CANCLD and missing values (nan) separately, depending on their role in your analysis.\n",
        "'''\n",
        "\n",
        "# Add the binary \"Default\" variable\n",
        "# 1 for \"CHGOFF\" (default), 0 for \"PIF\" or \"EXEMPT\"\n",
        "df_cleaned['Default'] = df_cleaned['LoanStatus'].apply(lambda x: 1 if x == 'CHGOFF' else 0)\n",
        "\n",
        "# Check the distribution of the new \"Default\" variable\n",
        "default_distribution = df_cleaned['Default'].value_counts()\n",
        "print(f\"Default distribution:\\n{default_distribution}\")\n",
        "\n",
        "# Save the updated dataset\n",
        "updated_path = '/content/drive/My Drive/MS&E246/cleaned_with_defaults.csv'\n",
        "df_cleaned.to_csv(updated_path, index=False)\n",
        "print(f\"Updated dataset with 'Default' variable saved to: {updated_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO-YKWb_-kYU",
        "outputId": "6fba596b-a726-4c40-d826-c9bdcfb281ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default distribution:\n",
            "Default\n",
            "0    175376\n",
            "1     12078\n",
            "Name: count, dtype: int64\n",
            "Updated dataset with 'Default' variable saved to: /content/drive/My Drive/MS&E246/cleaned_with_defaults.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature analysis: logit(P (Default=1))= b0+b1GrossAproval+B2*TermInMonths+B3*NaicsCode=B4ApprovalFiscalYear+B5JobsSupported+B6NaicsDescription\n",
        "\n",
        "#B6 is high dimensional. so lets prompt gemini to reduce the dimensionality of B6\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/My Drive/MS&E246/cleaned_with_defaults.csv'\n",
        "df = pd.read_csv(data_path, low_memory=False)\n",
        "\n",
        "# NAICS code mappings to Sectors\n",
        "naics_mapping = {\n",
        "    '11': 'Agriculture',       # Agriculture, Forestry, Fishing, and Hunting\n",
        "    '21': 'Mining',            # Mining, Quarrying, and Oil and Gas Extraction\n",
        "    '22': 'Utilities',         # Utilities\n",
        "    '23': 'Construction',      # Construction\n",
        "    '31': 'Manufacturing',     # Manufacturing\n",
        "    '32': 'Manufacturing',     # Manufacturing\n",
        "    '33': 'Manufacturing',     # Manufacturing\n",
        "    '42': 'Wholesale Trade',   # Wholesale Trade\n",
        "    '44': 'Retail Trade',      # Retail Trade\n",
        "    '45': 'Retail Trade',      # Retail Trade\n",
        "    '48': 'Transportation',    # Transportation and Warehousing\n",
        "    '49': 'Transportation',    # Transportation and Warehousing\n",
        "    '51': 'Information',       # Information\n",
        "    '52': 'Finance',           # Finance and Insurance\n",
        "    '53': 'Real Estate',       # Real Estate and Rental and Leasing\n",
        "    '54': 'Services',          # Professional, Scientific, and Technical Services\n",
        "    '55': 'Management',        # Management of Companies and Enterprises\n",
        "    '56': 'Administrative',    # Administrative and Support and Waste Management\n",
        "    '61': 'Services',          # Educational Services\n",
        "    '62': 'Services',          # Health Care and Social Assistance\n",
        "    '71': 'Entertainment',     # Arts, Entertainment, and Recreation\n",
        "    '72': 'Hospitality',       # Accommodation and Food Services\n",
        "    '81': 'Other',             # Other Services (except Public Administration)\n",
        "    '92': 'Public',            # Public Administration\n",
        "}\n",
        "\n",
        "# Helper function to map NAICS codes to Sectors\n",
        "def map_naics_code(code):\n",
        "    try:\n",
        "        if pd.notnull(code) and float(code) != 0.0:  # Exclude invalid codes\n",
        "            code = str(int(float(code)))  # Convert to string\n",
        "            naics_prefix = code[:2]  # Get the first 2 digits\n",
        "            return naics_mapping.get(naics_prefix, \"Other\")  # Map to category\n",
        "        return \"Other\"  # Default for missing or invalid codes\n",
        "    except ValueError:\n",
        "        return \"Other\"  # Handle unexpected non-numeric values\n",
        "\n",
        "# Map NaicsCode to Sectors\n",
        "df['Sector'] = df['NaicsCode'].apply(map_naics_code)\n",
        "\n",
        "# Display unique values in the Sector column\n",
        "if 'Sector' in df.columns:\n",
        "    unique_sectors = df['Sector'].unique()\n",
        "    print(\"Unique values in 'Sector' column:\")\n",
        "    print(unique_sectors)\n",
        "    print(f\"Total unique values: {len(unique_sectors)}\")\n",
        "else:\n",
        "    print(\"The 'Sector' column is not present in the dataset.\")\n",
        "\n",
        "# One-hot encode the Sector column\n",
        "df_encoded = pd.get_dummies(df, columns=['Sector'], prefix='Sector', drop_first=False)\n",
        "\n",
        "# Correct the one-hot encoded columns by replacing True/False with 1/0\n",
        "sector_columns = [col for col in df_encoded.columns if col.startswith('Sector_')]\n",
        "df_encoded[sector_columns] = df_encoded[sector_columns].replace({False: 0, True: 1})\n",
        "\n",
        "# Save the updated dataset with corrected sector columns\n",
        "output_path = '/content/drive/My Drive/MS&E246/cleaned_with_encoded_sector_corrected.csv'\n",
        "df_encoded.to_csv(output_path, index=False)\n",
        "\n",
        "# Print confirmation and dataset details\n",
        "print(f\"\\nUpdated dataset with corrected sector columns saved to: {output_path}\")\n",
        "print(f\"Shape of the dataset after encoding: {df_encoded.shape}\")\n",
        "print(\"\\nColumns in the dataset after encoding:\")\n",
        "print(df_encoded.columns.tolist())\n",
        "\n",
        "# Verify the encoding\n",
        "print(\"\\nSector column verification:\")\n",
        "for col in sector_columns:\n",
        "    print(f\"{col}: Unique values -> {df_encoded[col].unique()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4L-MXRjBaeJ",
        "outputId": "fbc6b1a5-723f-4363-ce7c-37771b2ae286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'Sector' column:\n",
            "['Other' 'Retail Trade' 'Wholesale Trade' 'Manufacturing' 'Administrative'\n",
            " 'Agriculture' 'Construction' 'Services' 'Transportation' 'Information'\n",
            " 'Mining' 'Entertainment' 'Real Estate' 'Hospitality' 'Public' 'Utilities'\n",
            " 'Management' 'Finance']\n",
            "Total unique values: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-06a588991ff5>:65: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_encoded[sector_columns] = df_encoded[sector_columns].replace({False: 0, True: 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated dataset with corrected sector columns saved to: /content/drive/My Drive/MS&E246/cleaned_with_encoded_sector_corrected.csv\n",
            "Shape of the dataset after encoding: (187454, 58)\n",
            "\n",
            "Columns in the dataset after encoding:\n",
            "['Program', 'TermInMonths', 'ApprovalFiscalYear', 'AsOfDate', 'BorrState', 'ThirdPartyLender_Name', 'BusinessAge', 'BorrZip', 'CDC_State', 'CDC_Name', 'BorrName', 'SBADistrictOffice', 'CDC_City', 'FranchiseName', 'ProjectState', 'JobsSupported', 'ApprovalDate', 'CDC_Zip', 'ChargeOffDate', 'ThirdPartyLender_State', 'FirstDisbursementDate', 'LoanStatus', 'NaicsDescription', 'PaidInFullDate', 'ThirdPartyDollars', 'NaicsCode', 'BorrStreet', 'Subprogram', 'FranchiseCode', 'ThirdPartyLender_City', 'GrossChargeOffAmount', 'CDC_Street', 'GrossApproval', 'BorrCity', 'BusinessType', 'DeliveryMethod', 'CongressionalDistrict', 'ProjectCounty', 'missingStatus', 'Default', 'Sector_Administrative', 'Sector_Agriculture', 'Sector_Construction', 'Sector_Entertainment', 'Sector_Finance', 'Sector_Hospitality', 'Sector_Information', 'Sector_Management', 'Sector_Manufacturing', 'Sector_Mining', 'Sector_Other', 'Sector_Public', 'Sector_Real Estate', 'Sector_Retail Trade', 'Sector_Services', 'Sector_Transportation', 'Sector_Utilities', 'Sector_Wholesale Trade']\n",
            "\n",
            "Sector column verification:\n",
            "Sector_Administrative: Unique values -> [0 1]\n",
            "Sector_Agriculture: Unique values -> [0 1]\n",
            "Sector_Construction: Unique values -> [0 1]\n",
            "Sector_Entertainment: Unique values -> [0 1]\n",
            "Sector_Finance: Unique values -> [0 1]\n",
            "Sector_Hospitality: Unique values -> [0 1]\n",
            "Sector_Information: Unique values -> [0 1]\n",
            "Sector_Management: Unique values -> [0 1]\n",
            "Sector_Manufacturing: Unique values -> [0 1]\n",
            "Sector_Mining: Unique values -> [0 1]\n",
            "Sector_Other: Unique values -> [1 0]\n",
            "Sector_Public: Unique values -> [0 1]\n",
            "Sector_Real Estate: Unique values -> [0 1]\n",
            "Sector_Retail Trade: Unique values -> [0 1]\n",
            "Sector_Services: Unique values -> [0 1]\n",
            "Sector_Transportation: Unique values -> [0 1]\n",
            "Sector_Utilities: Unique values -> [0 1]\n",
            "Sector_Wholesale Trade: Unique values -> [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic regression\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df[df['Default'] == 0]\n",
        "df_minority = df[df['Default'] == 1]\n",
        "\n",
        "# Undersample the majority class\n",
        "df_majority_undersampled = resample(df_majority,\n",
        "                                    replace=False,     # Sample without replacement\n",
        "                                    n_samples=len(df_minority),  # Match minority class size\n",
        "                                    random_state=42)   # Reproducibility\n",
        "\n",
        "# Combine undersampled majority class with the minority class\n",
        "df_balanced = pd.concat([df_majority_undersampled, df_minority])\n",
        "\n",
        "# Shuffle the data\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Shared independent variables\n",
        "shared_vars = ['GrossApproval', 'TermInMonths', 'ApprovalFiscalYear', 'JobsSupported']\n",
        "\n",
        "# Dynamically find all `Sector_*` columns\n",
        "sector_columns = [col for col in df_balanced.columns if col.startswith('Sector_')]\n",
        "\n",
        "# Split the sector columns into six groups\n",
        "sector_groups = [sector_columns[i::6] for i in range(6)]\n",
        "\n",
        "# Fit logistic regression models for each group\n",
        "results = []\n",
        "for i, group in enumerate(sector_groups):\n",
        "    print(f\"\\n--- Model {i + 1}: Including sectors {group} ---\")\n",
        "\n",
        "    # Define dependent and independent variables\n",
        "    independent_vars = shared_vars + group\n",
        "    df_subset = df_balanced[[dependent_var] + independent_vars].dropna()\n",
        "\n",
        "    X = df_subset[independent_vars]\n",
        "    y = df_subset[dependent_var]\n",
        "\n",
        "    # Add constant\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    # Fit logistic regression\n",
        "    try:\n",
        "        model = sm.Logit(y, X)\n",
        "        result = model.fit()\n",
        "        results.append(result)\n",
        "\n",
        "        # Print summary for the current model\n",
        "        print(result.summary())\n",
        "    except Exception as e:\n",
        "        print(f\"Error fitting Model {i + 1}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXUB7_yZbNz",
        "outputId": "f0602c1c-301c-43c7-937b-7675a9b5da7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model 1: Including sectors ['Sector_Administrative', 'Sector_Information', 'Sector_Real Estate'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.628623\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   No. Observations:                24156\n",
            "Model:                          Logit   Df Residuals:                    24148\n",
            "Method:                           MLE   Df Model:                            7\n",
            "Date:                Mon, 27 Jan 2025   Pseudo R-squ.:                 0.09309\n",
            "Time:                        03:57:09   Log-Likelihood:                -15185.\n",
            "converged:                       True   LL-Null:                       -16744.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "=========================================================================================\n",
            "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                   193.9114      4.572     42.416      0.000     184.951     202.872\n",
            "GrossApproval          1.988e-07   2.48e-08      8.028      0.000     1.5e-07    2.47e-07\n",
            "TermInMonths             -0.0081      0.001    -15.019      0.000      -0.009      -0.007\n",
            "ApprovalFiscalYear       -0.0957      0.002    -41.740      0.000      -0.100      -0.091\n",
            "JobsSupported            -0.0011      0.000     -2.468      0.014      -0.002      -0.000\n",
            "Sector_Administrative    -0.1023      0.105     -0.971      0.332      -0.309       0.104\n",
            "Sector_Information       -0.0134      0.151     -0.089      0.929      -0.310       0.283\n",
            "Sector_Real Estate        0.3043      0.090      3.397      0.001       0.129       0.480\n",
            "=========================================================================================\n",
            "\n",
            "--- Model 2: Including sectors ['Sector_Agriculture', 'Sector_Management', 'Sector_Retail Trade'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.627701\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   No. Observations:                24156\n",
            "Model:                          Logit   Df Residuals:                    24148\n",
            "Method:                           MLE   Df Model:                            7\n",
            "Date:                Mon, 27 Jan 2025   Pseudo R-squ.:                 0.09442\n",
            "Time:                        03:57:09   Log-Likelihood:                -15163.\n",
            "converged:                       True   LL-Null:                       -16744.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "=======================================================================================\n",
            "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "const                 193.8740      4.561     42.508      0.000     184.935     202.813\n",
            "GrossApproval        2.042e-07   2.48e-08      8.239      0.000    1.56e-07    2.53e-07\n",
            "TermInMonths           -0.0081      0.001    -15.125      0.000      -0.009      -0.007\n",
            "ApprovalFiscalYear     -0.0957      0.002    -41.836      0.000      -0.100      -0.091\n",
            "JobsSupported          -0.0009      0.000     -2.221      0.026      -0.002      -0.000\n",
            "Sector_Agriculture      0.1972      0.195      1.009      0.313      -0.186       0.580\n",
            "Sector_Management      -0.4904      0.756     -0.648      0.517      -1.973       0.992\n",
            "Sector_Retail Trade     0.3050      0.041      7.458      0.000       0.225       0.385\n",
            "=======================================================================================\n",
            "\n",
            "--- Model 3: Including sectors ['Sector_Construction', 'Sector_Manufacturing', 'Sector_Services'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.624960\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   No. Observations:                24156\n",
            "Model:                          Logit   Df Residuals:                    24148\n",
            "Method:                           MLE   Df Model:                            7\n",
            "Date:                Mon, 27 Jan 2025   Pseudo R-squ.:                 0.09837\n",
            "Time:                        03:57:10   Log-Likelihood:                -15097.\n",
            "converged:                       True   LL-Null:                       -16744.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "========================================================================================\n",
            "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------\n",
            "const                  186.7764      4.609     40.526      0.000     177.743     195.810\n",
            "GrossApproval         1.819e-07   2.51e-08      7.257      0.000    1.33e-07    2.31e-07\n",
            "TermInMonths            -0.0083      0.001    -15.105      0.000      -0.009      -0.007\n",
            "ApprovalFiscalYear      -0.0921      0.002    -39.808      0.000      -0.097      -0.088\n",
            "JobsSupported           -0.0011      0.000     -2.568      0.010      -0.002      -0.000\n",
            "Sector_Construction      0.1072      0.058      1.863      0.062      -0.006       0.220\n",
            "Sector_Manufacturing    -0.1948      0.045     -4.336      0.000      -0.283      -0.107\n",
            "Sector_Services         -0.4851      0.038    -12.894      0.000      -0.559      -0.411\n",
            "========================================================================================\n",
            "\n",
            "--- Model 4: Including sectors ['Sector_Entertainment', 'Sector_Mining', 'Sector_Transportation'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.627915\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   No. Observations:                24156\n",
            "Model:                          Logit   Df Residuals:                    24148\n",
            "Method:                           MLE   Df Model:                            7\n",
            "Date:                Mon, 27 Jan 2025   Pseudo R-squ.:                 0.09411\n",
            "Time:                        03:57:10   Log-Likelihood:                -15168.\n",
            "converged:                       True   LL-Null:                       -16744.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "=========================================================================================\n",
            "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                   192.6579      4.561     42.242      0.000     183.719     201.597\n",
            "GrossApproval          1.941e-07   2.48e-08      7.821      0.000    1.45e-07    2.43e-07\n",
            "TermInMonths             -0.0081      0.001    -15.065      0.000      -0.009      -0.007\n",
            "ApprovalFiscalYear       -0.0951      0.002    -41.563      0.000      -0.100      -0.091\n",
            "JobsSupported            -0.0011      0.000     -2.504      0.012      -0.002      -0.000\n",
            "Sector_Entertainment      0.5278      0.084      6.263      0.000       0.363       0.693\n",
            "Sector_Mining            -0.5653      0.454     -1.245      0.213      -1.455       0.325\n",
            "Sector_Transportation    -0.2232      0.110     -2.036      0.042      -0.438      -0.008\n",
            "=========================================================================================\n",
            "\n",
            "--- Model 5: Including sectors ['Sector_Finance', 'Sector_Other', 'Sector_Utilities'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.617741\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   No. Observations:                24156\n",
            "Model:                          Logit   Df Residuals:                    24148\n",
            "Method:                           MLE   Df Model:                            7\n",
            "Date:                Mon, 27 Jan 2025   Pseudo R-squ.:                  0.1088\n",
            "Time:                        03:57:10   Log-Likelihood:                -14922.\n",
            "converged:                       True   LL-Null:                       -16744.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "======================================================================================\n",
            "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "const                231.2602      5.007     46.188      0.000     221.447     241.074\n",
            "GrossApproval       1.769e-07   2.53e-08      6.980      0.000    1.27e-07    2.27e-07\n",
            "TermInMonths          -0.0074      0.001    -13.680      0.000      -0.008      -0.006\n",
            "ApprovalFiscalYear    -0.1143      0.003    -45.583      0.000      -0.119      -0.109\n",
            "JobsSupported         -0.0010      0.000     -2.313      0.021      -0.002      -0.000\n",
            "Sector_Finance         0.2507      0.105      2.379      0.017       0.044       0.457\n",
            "Sector_Other          -0.9174      0.041    -22.457      0.000      -0.997      -0.837\n",
            "Sector_Utilities      -1.0540      0.756     -1.394      0.163      -2.536       0.428\n",
            "======================================================================================\n",
            "\n",
            "--- Model 6: Including sectors ['Sector_Hospitality', 'Sector_Public', 'Sector_Wholesale Trade'] ---\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.614279\n",
            "         Iterations 6\n",
            "Error fitting Model 6: Singular matrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature selection\n",
        "'''\n",
        "Key Recommendations for Features\n",
        "Based on the results:\n",
        "\n",
        "Retain Common Predictors Across All Models:\n",
        "\n",
        "GrossApproval, TermInMonths, ApprovalFiscalYear, and JobsSupported are consistent, significant predictors.\n",
        "They should be included in any model predicting defaults.\n",
        "\n",
        "Include Significant Sector-Specific Variables:\n",
        "\n",
        "Based on sector p-values, include:\n",
        "Sector_Real Estate (from Model 1)\n",
        "Sector_Retail Trade (from Model 2)\n",
        "Sector_Manufacturing and Sector_Services (from Model 3)\n",
        "Sector_Entertainment and Sector_Transportation (from Model 4)\n",
        "Sector_Finance and Sector_Other (from Model 5)\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DhxWuexV55_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB Boost with survival: baseline\n",
        "\n",
        "\n",
        "!pip install lifelines  # Install lifelines for survival analysis\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from lifelines.utils import concordance_index  # Correct import\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Make sure the cleaned_with_defaults gets loaded\n",
        "data_path = '/content/drive/My Drive/MS&E246/cleaned_with_encoded_sector_corrected.csv'\n",
        "df = pd.read_csv(data_path, low_memory=False)\n",
        "\n",
        "# Convert date columns to datetime\n",
        "date_cols = ['ApprovalDate', 'ChargeOffDate', 'PaidInFullDate', 'AsOfDate']\n",
        "for col in date_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "# Define Survival Time and Censoring\n",
        "def calculate_survival_time(row):\n",
        "    if not pd.isna(row['ChargeOffDate']):  # Default occurred\n",
        "        return (row['ChargeOffDate'] - row['ApprovalDate']).days\n",
        "    elif not pd.isna(row['PaidInFullDate']):  # Paid in full\n",
        "        return (row['PaidInFullDate'] - row['ApprovalDate']).days\n",
        "    else:  # Censored\n",
        "        return (row['AsOfDate'] - row['ApprovalDate']).days\n",
        "\n",
        "# Apply the survival time calculation\n",
        "df['SurvivalTime'] = df.apply(calculate_survival_time, axis=1)\n",
        "\n",
        "# Define the censoring indicator\n",
        "df['Event'] = np.where(df['LoanStatus'] == 'CHGOFF', 1, 0)\n",
        "\n",
        "# Filter relevant columns and drop rows with missing data\n",
        "relevant_columns = ['SurvivalTime', 'Event', 'GrossApproval', 'TermInMonths',\n",
        "                   'ApprovalFiscalYear', 'JobsSupported']\n",
        "df = df[relevant_columns].dropna()\n",
        "\n",
        "# Split data based on proposed timeframes\n",
        "train_df = df[df['ApprovalFiscalYear'] <= 2006]  # Training: 1990–2006\n",
        "val_df = df[(df['ApprovalFiscalYear'] >= 2007) & (df['ApprovalFiscalYear'] <= 2015)]  # Validation: 2007–2015\n",
        "test_df = df[df['ApprovalFiscalYear'] >= 2016]  # Testing: 2016–2024\n",
        "\n",
        "# Separate features (X) and target variables (y)\n",
        "X_train = train_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_train = train_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "X_val = val_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_val = val_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "X_test = test_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_test = test_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "# Prepare the data for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train['SurvivalTime'])\n",
        "dval = xgb.DMatrix(X_val, label=y_val['SurvivalTime'])\n",
        "dtest = xgb.DMatrix(X_test, label=y_test['SurvivalTime'])\n",
        "\n",
        "# Define XGBoost parameters for survival\n",
        "params = {\n",
        "    'objective': 'survival:cox',  # Cox proportional hazards objective\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, 'validation')],\n",
        "                  early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Predict survival scores for the test set\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "# Evaluate the model using Concordance Index (C-Index)\n",
        "c_index = concordance_index(y_test['SurvivalTime'], -y_pred, y_test['Event'])\n",
        "print(f\"Concordance Index (C-Index): {c_index:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_model('/content/drive/My Drive/MS&E246/survival_xgboost_model.json')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdntH-nNAhGb",
        "outputId": "864f38d8-f2b5-45d7-d6a6-460e0f62a768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.11/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.7.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.11/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.1.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "[0]\tvalidation-cox-nloglik:10.21284\n",
            "[1]\tvalidation-cox-nloglik:10.21197\n",
            "[2]\tvalidation-cox-nloglik:10.21124\n",
            "[3]\tvalidation-cox-nloglik:10.21004\n",
            "[4]\tvalidation-cox-nloglik:10.21030\n",
            "[5]\tvalidation-cox-nloglik:10.20995\n",
            "[6]\tvalidation-cox-nloglik:10.20988\n",
            "[7]\tvalidation-cox-nloglik:10.21046\n",
            "[8]\tvalidation-cox-nloglik:10.21010\n",
            "[9]\tvalidation-cox-nloglik:10.21022\n",
            "[10]\tvalidation-cox-nloglik:10.21040\n",
            "[11]\tvalidation-cox-nloglik:10.21077\n",
            "[12]\tvalidation-cox-nloglik:10.21168\n",
            "[13]\tvalidation-cox-nloglik:10.21177\n",
            "[14]\tvalidation-cox-nloglik:10.21186\n",
            "[15]\tvalidation-cox-nloglik:10.21222\n",
            "Concordance Index (C-Index): 0.4330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB Boost with survival: including all features from logistic model\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/My Drive/MS&E246/cleaned_with_encoded_sector_corrected.csv'\n",
        "df = pd.read_csv(data_path, low_memory=False)\n",
        "\n",
        "# Convert date columns to datetime\n",
        "date_cols = ['ApprovalDate', 'ChargeOffDate', 'PaidInFullDate', 'AsOfDate']\n",
        "for col in date_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "# Calculate Survival Time\n",
        "def calculate_survival_time(row):\n",
        "    if not pd.isna(row['ChargeOffDate']):  # Default occurred\n",
        "        return (row['ChargeOffDate'] - row['ApprovalDate']).days\n",
        "    elif not pd.isna(row['PaidInFullDate']):  # Paid in full\n",
        "        return (row['PaidInFullDate'] - row['ApprovalDate']).days\n",
        "    else:  # Censored\n",
        "        return (row['AsOfDate'] - row['ApprovalDate']).days\n",
        "\n",
        "df['SurvivalTime'] = df.apply(calculate_survival_time, axis=1)\n",
        "\n",
        "# Define the censoring indicator\n",
        "df['Event'] = np.where(df['LoanStatus'] == 'CHGOFF', 1, 0)\n",
        "\n",
        "# Select the relevant features\n",
        "selected_features = [\n",
        "    'SurvivalTime', 'Event', 'GrossApproval', 'TermInMonths',\n",
        "    'ApprovalFiscalYear', 'JobsSupported', 'Sector_Real Estate',\n",
        "    'Sector_Retail Trade', 'Sector_Manufacturing', 'Sector_Services',\n",
        "    'Sector_Entertainment', 'Sector_Transportation',\n",
        "    'Sector_Finance', 'Sector_Other'\n",
        "]\n",
        "df = df[selected_features].dropna()\n",
        "\n",
        "# Split data based on proposed timeframes\n",
        "train_df = df[df['ApprovalFiscalYear'] <= 2006]  # Training: 1990–2006\n",
        "val_df = df[(df['ApprovalFiscalYear'] >= 2007) & (df['ApprovalFiscalYear'] <= 2015)]  # Validation: 2007–2015\n",
        "test_df = df[df['ApprovalFiscalYear'] >= 2016]  # Testing: 2016–2024\n",
        "\n",
        "# Separate features (X) and target variables (y)\n",
        "X_train = train_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_train = train_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "X_val = val_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_val = val_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "X_test = test_df.drop(['SurvivalTime', 'Event'], axis=1)\n",
        "y_test = test_df[['SurvivalTime', 'Event']]\n",
        "\n",
        "# Prepare the data for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train['SurvivalTime'])\n",
        "dval = xgb.DMatrix(X_val, label=y_val['SurvivalTime'])\n",
        "dtest = xgb.DMatrix(X_test, label=y_test['SurvivalTime'])\n",
        "\n",
        "# Define XGBoost parameters for survival\n",
        "params = {\n",
        "    'objective': 'survival:cox',  # Cox proportional hazards objective\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, 'validation')],\n",
        "                  early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Predict survival scores for the test set\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "# Evaluate the model using Concordance Index (C-Index)\n",
        "c_index = concordance_index(y_test['SurvivalTime'], -y_pred, y_test['Event'])\n",
        "print(f\"Concordance Index (C-Index): {c_index:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_model('/content/drive/My Drive/MS&E246/survival_xgboost_model.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhQhq2E_Omo4",
        "outputId": "e86fc253-3b31-44fd-b28a-31bef9431928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.11/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.7.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.11/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.1.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "[0]\tvalidation-cox-nloglik:10.21420\n",
            "[1]\tvalidation-cox-nloglik:10.21421\n",
            "[2]\tvalidation-cox-nloglik:10.21380\n",
            "[3]\tvalidation-cox-nloglik:10.21344\n",
            "[4]\tvalidation-cox-nloglik:10.21370\n",
            "[5]\tvalidation-cox-nloglik:10.21390\n",
            "[6]\tvalidation-cox-nloglik:10.21416\n",
            "[7]\tvalidation-cox-nloglik:10.21408\n",
            "[8]\tvalidation-cox-nloglik:10.21386\n",
            "[9]\tvalidation-cox-nloglik:10.21364\n",
            "[10]\tvalidation-cox-nloglik:10.21385\n",
            "[11]\tvalidation-cox-nloglik:10.21422\n",
            "[12]\tvalidation-cox-nloglik:10.21478\n",
            "Concordance Index (C-Index): 0.4896\n"
          ]
        }
      ]
    }
  ]
}