{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnD5f7yLWnus",
    "outputId": "b45c152e-394e-46ba-fe3d-e236a1769843"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\AppData\\Local\\Temp\\ipykernel_26532\\2243873096.py:17: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_10_present = pd.read_csv(path1_10_present)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read from folder ID path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\AppData\\Local\\Temp\\ipykernel_26532\\2243873096.py:18: DtypeWarning: Columns (12,13,14,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_91_09 = pd.read_csv(path1_91_09)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# Paths to your files\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# First attempt with folder ID\n",
    "path1_10_present = 'foia-504-fy2010-present-asof-240930.csv'\n",
    "path1_91_09 = 'foia-504-fy1991-fy2009-asof-240930.csv'\n",
    "\n",
    "# Second attempt with folder name\n",
    "path2_10_present = '/content/drive/My Drive/MS&E246/10_present.csv'\n",
    "path2_91_09 = '/content/drive/My Drive/MS&E246/91_09.csv'\n",
    "\n",
    "# Try reading with both paths\n",
    "try:\n",
    "    # Try first path\n",
    "    df_10_present = pd.read_csv(path1_10_present)\n",
    "    df_91_09 = pd.read_csv(path1_91_09)\n",
    "    print(\"Successfully read from folder ID path\")\n",
    "except:\n",
    "    try:\n",
    "        # Try second path\n",
    "        df_10_present = pd.read_csv(path2_10_present)\n",
    "        df_91_09 = pd.read_csv(path2_91_09)\n",
    "        print(\"Successfully read from folder name path\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1wRpdaNaYe2",
    "outputId": "c34c1494-0663-474e-ede6-da34de006098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in 10_present: True\n",
      "Duplicates in 91_09: True\n",
      "\n",
      "Example duplicates in 10_present:\n",
      "      AsOfDate  Program                   BorrName                BorrStreet  \\\n",
      "80   9/30/2024      504       1013 Enterprises LLC      1013 Lincoln Highway   \n",
      "150  9/30/2024      504  10820 Hemlock Avenue, LLC      10820 Hemlock Avenue   \n",
      "195  9/30/2024      504    1128 Petro Parkway, LLC    1128 Petroleum Parkway   \n",
      "308  9/30/2024      504           123 Western, LLC  123 North Western Avenue   \n",
      "528  9/30/2024      504                  1508, LLC  1508 Kaliste Saloom Road   \n",
      "\n",
      "         BorrCity BorrState  BorrZip  count  \n",
      "80   Schererville        IN    46375      2  \n",
      "150       Fontana        CA    92337      2  \n",
      "195     Broussard        LA    70518      2  \n",
      "308       Chicago        IL    60612      2  \n",
      "528     Lafayette        LA    70508      2  \n",
      "\n",
      "Example duplicates in 91_09:\n",
      "      AsOfDate  Program                        BorrName  \\\n",
      "236  9/30/2024      504               220PROPERTIES LLC   \n",
      "248  9/30/2024      504          24 CARROT CORRAL, INC.   \n",
      "376  9/30/2024      504  3D Machine, Inc.and Deno Enter   \n",
      "425  9/30/2024      504            403 PARCEL ST. CORP.   \n",
      "794  9/30/2024      504        A & Z PHARMACEUTICAL INC   \n",
      "\n",
      "                       BorrStreet        BorrCity BorrState  BorrZip  count  \n",
      "236  7454 7456 & 7458 N  LA CHOLL          TUCSON        AZ    85741      2  \n",
      "248  800 BLOCK N. YELLOWSTONE AVE       POCATELLO        ID    83201      2  \n",
      "376         112 EAST UNION STREET        GOODLAND        IN    47948      2  \n",
      "425                  P.O. BOX 680  CENTRAL SQUARE        NY    13036      2  \n",
      "794       75 NORTH INDUSTRY COURT       DEER PARK        NY    11729      2  \n"
     ]
    }
   ],
   "source": [
    "#What is the id of the dataset\n",
    "id_columns = ['AsOfDate', 'Program', 'BorrName', 'BorrStreet', 'BorrCity', 'BorrState', 'BorrZip']\n",
    "\n",
    "# Check for 10_present dataset\n",
    "duplicates_10 = df_10_present.groupby(id_columns).size().reset_index(name='count')\n",
    "has_duplicates_10 = any(duplicates_10['count'] > 1)\n",
    "\n",
    "# Check for 91_09 dataset\n",
    "duplicates_91 = df_91_09.groupby(id_columns).size().reset_index(name='count')\n",
    "has_duplicates_91 = any(duplicates_91['count'] > 1)\n",
    "\n",
    "print(\"Duplicates in 10_present:\", has_duplicates_10)\n",
    "print(\"Duplicates in 91_09:\", has_duplicates_91)\n",
    "\n",
    "# If there are duplicates, let's see some examples\n",
    "if has_duplicates_10:\n",
    "    print(\"\\nExample duplicates in 10_present:\")\n",
    "    print(duplicates_10[duplicates_10['count'] > 1].head())\n",
    "\n",
    "if has_duplicates_91:\n",
    "    print(\"\\nExample duplicates in 91_09:\")\n",
    "    print(duplicates_91[duplicates_91['count'] > 1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Preliminary Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_91_09, df_10_present])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5I-BLMpd9Kc",
    "outputId": "5666f2bf-57a5-47ef-f964-78f863a3d983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 218095\n",
      "\n",
      "Unique loan statuses before cleaning:\n",
      "LoanStatus\n",
      "PIF           107245\n",
      "EXEMPT         59555\n",
      "CANCLD         30641\n",
      "CHGOFF         12078\n",
      "NOT FUNDED      8226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final size after cleaning: 178877\n",
      "\n",
      "Unique loan statuses after cleaning:\n",
      "LoanStatus\n",
      "PIF       107244\n",
      "EXEMPT     59555\n",
      "CHGOFF     12078\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def preliminary_clean_loan_data(df):\n",
    "    # Make a copy to avoid modifying original data\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    print(\"Initial size:\", len(df_clean))\n",
    "\n",
    "    # 1. Clean Loan Status\n",
    "    if 'Status' in df_clean.columns:\n",
    "        status_col = 'Status'\n",
    "    elif 'LoanStatus' in df_clean.columns:\n",
    "        status_col = 'LoanStatus'\n",
    "\n",
    "    # Print unique statuses before cleaning\n",
    "    print(\"\\nUnique loan statuses before cleaning:\")\n",
    "    print(df_clean[status_col].value_counts())\n",
    "\n",
    "    # Remove canceled and not funded loans but keep CHGOFF with zero charge-off\n",
    "    canceled_mask = df_clean[status_col].str.contains('CANCLD|CANCEL|Canceled|NOT FUNDED', na=False, case=False)\n",
    "    df_clean = df_clean[~canceled_mask]\n",
    "\n",
    "    # 2. Check monetary values\n",
    "    monetary_cols = ['GrossApproval', 'ThirdPartyDollars', 'GrossChargeOffAmount']\n",
    "    for col in monetary_cols:\n",
    "        if col in df_clean.columns:\n",
    "            # Remove negative values\n",
    "            df_clean = df_clean[df_clean[col].fillna(0) >= 0]\n",
    "\n",
    "    # 3. Check dates\n",
    "    date_cols = ['AsOfDate', 'ApprovalDate', 'PaidInFullDate']\n",
    "\n",
    "    for col in date_cols:\n",
    "        if col in df_clean.columns:\n",
    "            # Convert to datetime\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "\n",
    "            # Remove future dates (except AsOfDate which might be a reporting date)\n",
    "            if col != 'AsOfDate':\n",
    "                df_clean = df_clean[\n",
    "                    (df_clean[col].isna()) |\n",
    "                    (df_clean[col] <= pd.Timestamp.now())\n",
    "                ]\n",
    "\n",
    "    # 4. Check logical consistency\n",
    "    # PaidInFullDate should be after ApprovalDate\n",
    "    if 'PaidInFullDate' in df_clean.columns and 'ApprovalDate' in df_clean.columns:\n",
    "        df_clean = df_clean[\n",
    "            ~((df_clean['PaidInFullDate'].notna()) &\n",
    "              (df_clean['PaidInFullDate'] < df_clean['ApprovalDate']))\n",
    "        ]\n",
    "\n",
    "    # 5. Remove rows with missing crucial information\n",
    "    crucial_cols = ['BorrName', 'GrossApproval', status_col]\n",
    "    df_clean = df_clean.dropna(subset=crucial_cols)\n",
    "\n",
    "    print(\"\\nFinal size after cleaning:\", len(df_clean))\n",
    "    print(\"\\nUnique loan statuses after cleaning:\")\n",
    "    print(df_clean[status_col].value_counts())\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Clean both datasets\n",
    "df_clean = preliminary_clean_loan_data(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = \"2016-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Process loans with approval date before CUTOFF as training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1.1 Loans that have approval date before CUTOFF and are in EXEMPT state\n",
    "\n",
    "df_before_and_exempt = df_clean[(df_clean[\"ApprovalDate\"] < CUTOFF) & (df_clean[\"LoanStatus\"] == \"EXEMPT\")]\n",
    "# Not default\n",
    "df_before_and_exempt[\"Default\"] = False\n",
    "# Survival time is (CUTOFF - approval date)\n",
    "df_before_and_exempt[\"SurvivalDays\"] = (datetime.strptime(CUTOFF, '%Y-%m-%d') - df_before_and_exempt[\"ApprovalDate\"]).dt.days\n",
    "# Loss at default is 0\n",
    "df_before_and_exempt[\"LossAtDefault\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1.2 Loans that have approval date before CUTOFF and are in PIF state\n",
    "\n",
    "# 3.1.2(a) PaidInFullDate before CUTOFF: treat as paid at maturity\n",
    "df_before_and_pif_1 = df_clean[(df_clean[\"ApprovalDate\"] < CUTOFF) & (df_clean[\"LoanStatus\"] == \"PIF\") & (df_clean[\"PaidInFullDate\"] <= CUTOFF)]\n",
    "# Not default\n",
    "df_before_and_pif_1[\"Default\"] = False\n",
    "# Survival time is the term\n",
    "df_before_and_pif_1[\"SurvivalDays\"] = df_before_and_pif_1[\"TermInMonths\"] * 30\n",
    "# Loss at default is 0\n",
    "df_before_and_pif_1[\"LossAtDefault\"] = 0\n",
    "\n",
    "# 3.1.2(b) PaidInFullDate after CUTOFF: treat as EXEMPT\n",
    "df_before_and_pif_2 = df_clean[(df_clean[\"ApprovalDate\"] < CUTOFF) & (df_clean[\"LoanStatus\"] == \"PIF\") & (df_clean[\"PaidInFullDate\"] > CUTOFF)]\n",
    "# Not default\n",
    "df_before_and_pif_2[\"Default\"] = False\n",
    "# Survival time is (CUTOFF - approval date)\n",
    "df_before_and_pif_2[\"SurvivalDays\"] = (datetime.strptime(CUTOFF, '%Y-%m-%d') - df_before_and_pif_2[\"ApprovalDate\"]).dt.days\n",
    "# Loss at default is 0\n",
    "df_before_and_pif_2[\"LossAtDefault\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1.3 Loans that have approval date before CUTOFF and are in CHGOFF state\n",
    "\n",
    "df_before_and_chgoff = df_clean[(df_clean[\"ApprovalDate\"] < CUTOFF) & (df_clean[\"LoanStatus\"] == \"CHGOFF\")]\n",
    "df_before_and_chgoff[\"ChargeOffDate\"] = df_before_and_chgoff[\"ChargeOffDate\"].apply(pd.to_timedelta,unit = 'D') + datetime.strptime(\"1900-01-01\", '%Y-%m-%d')\n",
    "# Default is true\n",
    "df_before_and_chgoff[\"Default\"] = True\n",
    "# Survival time is (charge off date - approval date)\n",
    "df_before_and_chgoff[\"SurvivalDays\"] = (df_before_and_chgoff[\"ChargeOffDate\"] - df_before_and_chgoff[\"ApprovalDate\"]).dt.days\n",
    "# Loss at default is gross charge off amount\n",
    "df_before_and_chgoff[\"LossAtDefault\"] = df_before_and_chgoff[\"GrossChargeOffAmount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 132540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\AppData\\Local\\Temp\\ipykernel_26532\\3210809056.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_train = pd.concat([df_before_and_exempt, df_before_and_pif_1, df_before_and_pif_2, df_before_and_chgoff])\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([df_before_and_exempt, df_before_and_pif_1, df_before_and_pif_2, df_before_and_chgoff])\n",
    "print(\"Size of training set:\", len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Process loans with approval date after CUTOFF as testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2.1 Loans that have approval date after CUTOFF and are in EXEMPT state\n",
    "\n",
    "df_after_and_exempt = df_clean[(df_clean[\"ApprovalDate\"] >= CUTOFF) & (df_clean[\"LoanStatus\"] == \"EXEMPT\")]\n",
    "# Not default\n",
    "df_after_and_exempt[\"Default\"] = False\n",
    "# Survival time is (as of date - approval date)\n",
    "df_after_and_exempt[\"SurvivalDays\"] = (df_after_and_exempt[\"AsOfDate\"] - df_after_and_exempt[\"ApprovalDate\"]).dt.days\n",
    "# Loss at default is 0\n",
    "df_after_and_exempt[\"LossAtDefault\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2.2 Loans that have approval date after CUTOFF and are in PIF state: all treat as paid at maturity\n",
    "df_after_and_pif = df_clean[(df_clean[\"ApprovalDate\"] >= CUTOFF) & (df_clean[\"LoanStatus\"] == \"PIF\")]\n",
    "# Not default\n",
    "df_after_and_pif[\"Default\"] = False\n",
    "# Survival time is the term\n",
    "df_after_and_pif[\"SurvivalDays\"] = df_after_and_pif[\"TermInMonths\"] * 30\n",
    "# Loss at default is 0\n",
    "df_after_and_pif[\"LossAtDefault\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2.3 Loans that have approval date after CUTOFF and are in CHGOFF state\n",
    "\n",
    "df_after_and_chgoff = df_clean[(df_clean[\"ApprovalDate\"] >= CUTOFF) & (df_clean[\"LoanStatus\"] == \"CHGOFF\")]\n",
    "df_after_and_chgoff[\"ChargeOffDate\"] = df_after_and_chgoff[\"ChargeOffDate\"].apply(pd.to_timedelta,unit = 'D') + datetime.strptime(\"1900-01-01\", '%Y-%m-%d')\n",
    "# Default is true\n",
    "df_after_and_chgoff[\"Default\"] = True\n",
    "# Survival time is (charge off date - approval date)\n",
    "df_after_and_chgoff[\"SurvivalDays\"] = (df_after_and_chgoff[\"ChargeOffDate\"] - df_after_and_chgoff[\"ApprovalDate\"]).dt.days\n",
    "# Loss at default is gross charge off amount\n",
    "df_after_and_chgoff[\"LossAtDefault\"] = df_after_and_chgoff[\"GrossChargeOffAmount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing set: 46337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\AppData\\Local\\Temp\\ipykernel_26532\\2429493966.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_test = pd.concat([df_after_and_exempt, df_after_and_pif, df_after_and_chgoff])\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.concat([df_after_and_exempt, df_after_and_pif, df_after_and_chgoff])\n",
    "print(\"Size of testing set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Data Exploration: Test of Feature Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"NaicsCodeBigCategory\"] = df_train[\"NaicsCode\"].apply(lambda x: str(x)[:2])\n",
    "df_train[\"JS20\"] = df_train[\"JobsSupported\"]>20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Feature</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaicsCodeBigCategory</td>\n",
       "      <td>2485.698730</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BorrState</td>\n",
       "      <td>1639.732772</td>\n",
       "      <td>2.262880e-308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ProjectState</td>\n",
       "      <td>1621.465405</td>\n",
       "      <td>8.761926e-304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeliveryMethod</td>\n",
       "      <td>384.455856</td>\n",
       "      <td>6.346604e-82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subprogram</td>\n",
       "      <td>322.226754</td>\n",
       "      <td>1.537135e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JS20</td>\n",
       "      <td>40.343651</td>\n",
       "      <td>2.129965e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BusinessType</td>\n",
       "      <td>20.471881</td>\n",
       "      <td>3.585812e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ThirdPartyLender_Name_FirstLetterUpper</td>\n",
       "      <td>1.996780</td>\n",
       "      <td>1.576338e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Candidate Feature         Chi2        p-value\n",
       "3                    NaicsCodeBigCategory  2485.698730   0.000000e+00\n",
       "0                               BorrState  1639.732772  2.262880e-308\n",
       "4                            ProjectState  1621.465405  8.761926e-304\n",
       "1                          DeliveryMethod   384.455856   6.346604e-82\n",
       "2                              Subprogram   322.226754   1.537135e-69\n",
       "6                                    JS20    40.343651   2.129965e-10\n",
       "5                            BusinessType    20.471881   3.585812e-05\n",
       "7  ThirdPartyLender_Name_FirstLetterUpper     1.996780   1.576338e-01"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "candidates = [\"BorrState\", \"DeliveryMethod\", \"Subprogram\", \"NaicsCodeBigCategory\", \"ProjectState\", \"BusinessType\", \"JS20\"]\n",
    "chi2s = []\n",
    "pvalues = []\n",
    "\n",
    "for col in candidates:\n",
    "    df_train_not_na = df_train[~df_train[col].isna()]\n",
    "    cross_tab = pd.crosstab(df_train_not_na[col], df_train_not_na[\"Default\"])\n",
    "    chi2_results = chi2_contingency(cross_tab)\n",
    "    chi2s.append(float(chi2_results.statistic))\n",
    "    pvalues.append(float(chi2_results.pvalue))\n",
    "\n",
    "candidates.append(\"ThirdPartyLender_Name_FirstLetterUpper\")\n",
    "df_train_not_na = df_train[~df_train[\"ThirdPartyLender_Name\"].isna()]\n",
    "cross_tab = pd.crosstab(df_train_not_na[\"ThirdPartyLender_Name\"].apply(lambda x:x[0].isupper()), df_train_not_na[\"Default\"])\n",
    "chi2_results = chi2_contingency(cross_tab)\n",
    "chi2s.append(float(chi2_results.statistic))\n",
    "pvalues.append(float(chi2_results.pvalue))\n",
    "\n",
    "result = pd.DataFrame({\"Candidate Feature\":candidates, \"Chi2\":chi2s, \"p-value\":pvalues}).sort_values(by='p-value')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
